#!/usr/bin/python
# TODO:
# - Validate/Sanitize Input
# - Multiple CVEs
# - - As List
# - - Sequential Input
# - - Peak Version
# - RHEL/CentOS
#
# - Populate to persistent local database
# - - Check for updated entries?
import feedparser
from lxml import html
import requests
import sys

found = 0
cve = None
while cve is None:
	try:
            cve = sys.argv[1]
        except IndexError:
            cve = raw_input("CVE? ")

cve = cve.upper()
print cve
while found == 0:
    print "Starting feedparser"
    d = feedparser.parse('https://usn.ubuntu.com/usn/rss.xml')
    for e in d.entries:
        if e.summary.find(cve) > -1:
            print cve
            print e.link
            found = 1
            break
    if found == 1:
        break

    print "Starting page parser"
    pNum = 1
    while found == 0:
        if pNum == 1:
            url = 'https://usn.ubuntu.com/'
        else:
            url = 'https://usn.ubuntu.com/page/'+str(pNum)+'/'
        print "Loop: "+str(pNum)
        print "URL: "+url
        page = requests.get(url)
        tree = html.fromstring(page.content)
        links = tree.xpath('//h3[@class="p-heading--four"]/a')
        for l in links:
            print l.text_content()
            print l.values()
            detpage = requests.get(l.values()[0])
            dettree = html.fromstring(detpage.content)
            reflinks = dettree.xpath('//div[@class="col-8"]/ul/li/a')
            for rl in reflinks:
                print rl.text_content()
                print rl.values()
                if rl.text_content().find(cve) > -1:
                    found = 1
                    print
                    print "ITEM FOUND:"
                    print cve
                    print url
                    print l.values()[0]
                    print rl.values()[0]
                    sys.exit()
        if found == 1:
            break
        else:
            pNum = pNum + 1
            print "Not found on page"
            print
        
    if found == 1:
        break
